{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os \n",
    "os.chdir(\"/home/pengq/LenskAI/geneDRAGNN/models\")\n",
    "\n",
    "np.random.seed(314159) # set random seed\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.loader\n",
    "\n",
    "import wandb\n",
    "\n",
    "import models\n",
    "from data_utils import read_data, create_data\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/final_data/'\n",
    "\n",
    "model_creator_dict = {'SGConv': models.create_SGConv_GNN,\n",
    "                      'GraphSAGE': models.create_GraphSAGE_GNN,\n",
    "                      'TAG': models.create_TAG_GNN,\n",
    "                      'ClusterGCN': models.create_clusterGCN_GNN,\n",
    "                      'MLP': models.create_MLP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dataset, edge_list, labels = read_data(node_filepath=\"../data/final_data/node_node2vec_data.csv\",\n",
    "                                            label_filepath=\"../data/final_data/training_labels_trials.csv\",\n",
    "                                            edgelist_path=\"../data/final_data/ls-fgin_edge_list.edg\",\n",
    "                                            feats_type='nodeonly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_features = len(node_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_name = 'train_gnn_model.ipynb'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = notebook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn import metrics\n",
    "\n",
    "def run_trials(create_model, start_trial=0, end_trial=100, n_epochs=500, log=False, log_project=None):\n",
    "\n",
    "    if log:\n",
    "        # dt_string = str(datetime.datetime.today()).replace(' ', '_')\n",
    "        if log_project is None:\n",
    "            print('Enter the name of the log project: ')\n",
    "            log_project = input()\n",
    "\n",
    "    # model info\n",
    "    model = create_model()\n",
    "    model_summary = pl.utilities.model_summary.summarize(model, max_depth=4)\n",
    "    model_summary_str = str(model_summary)\n",
    "    num_trainable_params = model_summary.trainable_parameters\n",
    "\n",
    "    print(model_summary_str)\n",
    "\n",
    "    train_reports = []\n",
    "    test_reports = []\n",
    "    roc_data = []\n",
    "\n",
    "    for trial in tqdm(range(start_trial, end_trial + 1)):\n",
    "\n",
    "        print(f'running trial {str(trial)}')\n",
    "        data = create_data(node_dataset, edge_list, labels, f'label_{trial}', test_size=0.2, val_size=0.1)\n",
    "\n",
    "\n",
    "        model = create_model()\n",
    "\n",
    "        if log:\n",
    "            n_zfills = int(np.ceil(np.log10(100)))\n",
    "            log_name = f'{log_project}_trial{str(trial).zfill(n_zfills)}'\n",
    "\n",
    "            logger = WandbLogger(name=log_name, project=log_project, log_model=\"\\all\\\\\", save_dir='wandb_projects')\n",
    "\n",
    "            logger.log_metrics({'model_summary_str': model_summary_str,\n",
    "                                'num_trainable_params': num_trainable_params})\n",
    "            \n",
    "            # log random train-val-test split\n",
    "            logger.log_metrics({'train_mask': data.train_mask, 'val_mask': data.val_mask, 'test_mask': data.test_mask})\n",
    "\n",
    "        else:\n",
    "            logger = False\n",
    "\n",
    "        AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "\n",
    "        data_loader = torch_geometric.loader.DataLoader([data], batch_size=1, num_workers=os.cpu_count())\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "                    callbacks=[ModelCheckpoint(save_weights_only=False, mode=\"max\", monitor='val_acc')],\n",
    "                    # gpus=AVAIL_GPUS,\n",
    "                    accelerator = \"gpu\",\n",
    "                    devices=AVAIL_GPUS,\n",
    "                    max_epochs=n_epochs,\n",
    "                    logger=logger,\n",
    "                    enable_model_summary=False\n",
    "                    # progress_bar_refresh_rate=0,\n",
    "                    )\n",
    "\n",
    "        trainer.fit(model, data_loader, data_loader)\n",
    "\n",
    "        model = models.LitGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "        train_report, test_report = model_utils.evaluate_model(model, data, logger=logger)\n",
    "\n",
    "        train_reports.append(train_report)\n",
    "        test_reports.append(test_report)\n",
    "\n",
    "        model.to(device='cuda')\n",
    "        logits, _, _ = model.forward(data.to(device='cuda'))\n",
    "\n",
    "        preds = logits[data.test_mask][:, 1].cpu().detach().numpy()\n",
    "        y = data.y[data.test_mask].cpu().detach().numpy()\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, preds)\n",
    "        auc_score = metrics.roc_auc_score(y, preds)\n",
    "\n",
    "        roc_data.append({'fpr': fpr, 'tpr': tpr, 'threholds': thresholds, 'auc': auc_score})\n",
    "\n",
    "        if log:\n",
    "            logger.log_metrics({'auc_test': auc_score, 'fpr_test': fpr, \n",
    "                                'tpr_test': tpr, 'roc_thres': thresholds})\n",
    "\n",
    "        if log:\n",
    "            wandb.save('modeling_gnn.ipynb')\n",
    "            wandb.finish(quiet=True)\n",
    "\n",
    "        del model, data_loader, trainer, data\n",
    "        gc.collect()\n",
    "\n",
    "        print('memory allocated: ', torch.cuda.memory_allocated())\n",
    "        print('memory reserved: ', torch.cuda.memory_reserved())\n",
    "        torch.cuda.empty_cache()\n",
    "        print('\\\\nafter empty_cache:')\n",
    "        print('memory allocated: ', torch.cuda.memory_allocated())\n",
    "        print('memory reserved: ', torch.cuda.memory_reserved())\n",
    "\n",
    "\n",
    "\n",
    "    return train_reports, test_reports, roc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_list.head())\n",
    "edge_list.iloc[:, :2] = edge_list.iloc[:, :2].apply(pd.to_numeric, errors='coerce')\n",
    "edge_list = edge_list.dropna().astype(int)\n",
    "edge_index = torch.tensor(edge_list.iloc[:, :2].to_numpy().T, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN AND EVALUATE MODEL\n",
    "\n",
    "model_name = 'SGConv'\n",
    "create_model = model_creator_dict[model_name]\n",
    "\n",
    "log_project_name = f'{model_name}'\n",
    "\n",
    "# run multiple trials\n",
    "train_reports, test_reports, roc_data = run_trials(lambda: create_model(model_name, num_features, num_classes), start_trial=0, end_trial=0,\n",
    "                                         n_epochs=250, log=False, log_project=log_project_name)\n",
    "\n",
    "# save reports from trials to json\n",
    "model_utils.save_reports(f'project_reports/{log_project_name}_reports', train_reports, test_reports)\n",
    "np.save(f'project_reports/{model_name}_roc', roc_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
